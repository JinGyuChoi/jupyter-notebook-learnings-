{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRResnet-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, PReLU, LeakyReLU, Layer, Conv2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, channel=64, kernel_size=(3, 3)):\n",
    "        super().__init__()\n",
    "        #conv - bn - prelu - conv - bn - elementwise sum(residual)\n",
    "        # No bias in conv layer when used with batch_norm layer\n",
    "        self.conv1 = Conv2D(channel, kernel_size, padding = 'same', use_bias=False)\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.prelu = PReLU()\n",
    "        self.conv2 = Conv2D(channel, kernel_size, padding = 'same', use_bias=False)\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        h = self.prelu(self.bn1(self.conv1(x), training))\n",
    "        return x + self.bn2(self.conv2(h), training) # residual : elementwise sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv-Bn-Relu Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnLReluBlock(Layer):\n",
    "    #in discriminater, conv - bn - leaky relu\n",
    "    def __init__(self, channel=64, kernel_size=(3, 3)):\n",
    "        super().__init__()\n",
    "        self.conv = Conv2D(channel, kernel_size, padding = 'same', use_bias=False)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.lrelu = LeakyReLU()\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        return self.lrelu(self.bn(self.conv(x), training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator (SRResnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    # the whole network : input(x) - conv - prelu - (resblocks*num_resblock) - conv - bn - prelu - conv - skip_connection\n",
    "    # - conv - pixelshuffler - prelu - conv - pixelshuffler - prelu - conv\n",
    "    def __init__(self, channel=64, num_resblock=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(channel, (9,9), padding = 'same')\n",
    "        self.prelu1 = PReLU()\n",
    "        \n",
    "        self.resblock_list = [ResidualBlock(channel, (3,3)) for _ in range(num_resblock)]\n",
    "        \n",
    "        self.conv2 = Conv2D(channel, (3,3), padding = 'same', use_bias=False)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.prelu2 = PReLU()\n",
    "        \n",
    "        self.conv3 = Conv2D(channel * 4, (3,3), padding = 'same')\n",
    "        self.prelu3 = PReLU()\n",
    "        \n",
    "        \n",
    "        self.conv4 = Conv2D(channel * 4, (3,3), padding = 'same')\n",
    "        self.prelu4 = PReLU()\n",
    "        self.conv5 = Conv2D(3, (9,9), padding = 'same')\n",
    "        \n",
    "    def call(self, x, training=None, mask=None):\n",
    "        h = self.prelu1(self.conv1(x))\n",
    "        h_skip = h\n",
    "        \n",
    "        for resblock in self.resblock_list:\n",
    "            h = resblock(h, training)\n",
    "            \n",
    "        h = self.prelu2(self.bn(self.conv2(h), training))\n",
    "        h = h + h_skip\n",
    "        \n",
    "        h = self.prelu3(tf.nn.depth_to_space(self.conv3(h),2)) #pixel shuffler -> x2\n",
    "        h = self.prelu4(tf.nn.depth_to_space(self.conv4(h),2))\n",
    "        \n",
    "        return self.conv5(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self, channel=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(channel, (3,3), padding = 'same')\n",
    "        self.lrelu1 = LeakyReLU()\n",
    "        \n",
    "        self.block_list = []\n",
    "        self.block_list.append(ConvBnLReluBlock(channel))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 2))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 2))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 4))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 4))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 8))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 8))\n",
    "        #self.block_list.append(ConvBnLReluBlock(channel * 16))\n",
    "        #self.block_list.append(ConvBnLReluBlock(channel * 16))\n",
    "        #self.block_list.append(ConvBnLReluBlock(channel * 32))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(1024)\n",
    "        self.lrelu2 = LeakyReLU()\n",
    "        self.dense2 = Dense(1, activation = 'sigmoid')\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        h = self.lrelu1(self.conv1(x))\n",
    "        for block in self.block_list:\n",
    "            h = block(h, training)\n",
    "        h = self.flatten(h)\n",
    "        h = self.lrelu2(self.dense1(h)) #\n",
    "        return self.dense2(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (Caltech101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(name='caltech101', split='train')\n",
    "dataset = dataset.map(lambda x: (tf.image.resize(tf.cast(x['image'], tf.float32), (8, 8), tf.image.ResizeMethod.BICUBIC) / 255.0,\n",
    "                                 tf.image.resize(tf.cast(x['image'], tf.float32), (32, 32), tf.image.ResizeMethod.BICUBIC) / 255.0)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Model, Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(16) # originally 64, costomized considering memory\n",
    "discriminator = Discriminator(16)\n",
    "\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "vgg = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "vgg.trainable = False\n",
    "\n",
    "w_gan = 1e-2\n",
    "w_vgg = 1e-5\n",
    "\n",
    "optim_d = tf.optimizers.Adam(1e-4)\n",
    "optim_g = tf.optimizers.Adam(1e-4)\n",
    "\n",
    "d_mean = tf.metrics.Mean()\n",
    "g_mean = tf.metrics.Mean()\n",
    "vgg_mean = tf.metrics.Mean()\n",
    "l1_mean = tf.metrics.Mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def l1_loss_func(y, y_):\n",
    "    return tf.reduce_mean(tf.abs(y - y_))\n",
    "\n",
    "@tf.function\n",
    "def vgg_loss_func(y, y_):\n",
    "    return tf.reduce_mean((vgg(y) - vgg(y_)) ** 2)\n",
    "\n",
    "@tf.function\n",
    "def discriminator_loss(real, fake):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real), real)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake), fake)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "@tf.function\n",
    "def generator_loss(fake):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake), fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image_lr, image_hr, optim_d, optim_g):\n",
    "    with tf.GradientTape() as tape_g, tf.GradientTape() as tape_d:\n",
    "        image_sr = generator(image_lr, training = True)\n",
    "        \n",
    "        d_real = discriminator(image_hr, training = True)\n",
    "        d_fake = discriminator(image_sr, training = True)\n",
    "        \n",
    "        d_loss = discriminator_loss(d_real, d_fake)\n",
    "        g_loss = generator_loss(d_fake)\n",
    "        \n",
    "        vgg_loss = vgg_loss_func(image_hr, image_sr)\n",
    "        l1_loss = l1_loss_func(image_hr, image_sr)\n",
    "        \n",
    "        loss = w_gan * g_loss + w_vgg * vgg_loss + l1_loss\n",
    "        \n",
    "        gradients_d = tape_d.gradient(d_loss, discriminator.trainable_weights)\n",
    "        gradients_g = tape_g.gradient(loss, generator.trainable_weights)\n",
    "        \n",
    "    optim_d.apply_gradients(zip(gradients_d, discriminator.trainable_weights))\n",
    "    optim_g.apply_gradients(zip(gradients_g, generator.trainable_weights))\n",
    "    \n",
    "    return d_loss, g_loss, vgg_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for img_lr, img_hr in dataset:\n",
    "        d_loss, g_loss, vgg_loss, l1_loss = train_step(img_lr, img_hr, optim_d, optim_g)\n",
    "\n",
    "        d_mean.update_state(d_loss)\n",
    "        g_mean.update_state(g_loss)\n",
    "        vgg_mean.update_state(vgg_loss)\n",
    "        l1_mean.update_state(l1_loss)\n",
    "\n",
    "    print('epoch: {}, d_loss: {}, g_loss: {}, vgg_loss: {}, l1_loss: {}'.format(epoch+1,\n",
    "                                                                d_mean.result(),\n",
    "                                                                g_mean.result(),\n",
    "                                                                vgg_mean.result(),\n",
    "                                                                l1_mean.result()))\n",
    "    img_sr_list = list()\n",
    "    img_lr_list = list()\n",
    "    img_hr_list = list()\n",
    "    for img_lr, img_hr in dataset.take(10):\n",
    "        img_sr = generator(img_lr)\n",
    "        \n",
    "        img_lr_list.append(tf.image.resize(img_lr[0], (32, 32),\n",
    "                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR))\n",
    "        img_sr_list.append(img_sr[0])\n",
    "        img_hr_list.append(img_hr[0])\n",
    "    \n",
    "    img_lr = np.concatenate(img_lr_list, axis=1)\n",
    "    img_sr = np.concatenate(img_sr_list, axis=1)\n",
    "    img_hr = np.concatenate(img_hr_list, axis=1)\n",
    "    img = np.concatenate([img_lr, img_sr, img_hr], axis=0)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    d_mean.reset_states()\n",
    "    g_mean.reset_states()\n",
    "    vgg_mean.reset_states()\n",
    "    l1_mean.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
